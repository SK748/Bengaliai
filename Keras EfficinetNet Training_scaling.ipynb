{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import Dense, Lambda\n",
    "from math import ceil\n",
    "\n",
    "# Install EfficientNet\n",
    "#!pip install '../input/kerasefficientnetb3/efficientnet-1.0.0-py3-none-any.whl'\n",
    "import efficientnet.keras as efn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import warnings\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "\n",
    "#sklearns \n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# keras modules \n",
    "from keras.applications.densenet import DenseNet121, DenseNet169, DenseNet201\n",
    "from keras.optimizers import Adam, Nadam, SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout, Conv2D, GlobalMaxPooling2D, concatenate\n",
    "from keras.layers import (MaxPooling2D, Input, Average, Activation, MaxPool2D,\n",
    "                          Flatten, LeakyReLU, BatchNormalization)\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "from keras.utils import Sequence\n",
    "from keras import utils as np_utils\n",
    "from keras.callbacks import (Callback, ModelCheckpoint,\n",
    "                                        LearningRateScheduler,EarlyStopping, \n",
    "                                        ReduceLROnPlateau,CSVLogger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm.auto import tqdm\n",
    "from glob import glob\n",
    "from keras.utils import Sequence\n",
    "\n",
    "from tensorflow import keras\n",
    "import matplotlib.image as mpimg\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.models import clone_model\n",
    "from keras.layers import Dense,Conv2D,Flatten,MaxPool2D,Dropout,BatchNormalization, Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import PIL.Image as Image, PIL.ImageDraw as ImageDraw, PIL.ImageFont as ImageFont\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Modules\n",
    "import time, gc\n",
    "from math import floor\n",
    "# Keras\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "\n",
    "# Iterative-Stratification\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold, MultilabelStratifiedShuffleSplit\n",
    "\n",
    "# Custom \n",
    "from preprocessing import generate_images, resize_image\n",
    "from model import create_model\n",
    "from utils import plot_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_ = pd.read_csv('./bengaliai_cv19/train.csv')\n",
    "test_df_ = pd.read_csv('./bengaliai_cv19/test.csv')\n",
    "class_map_df = pd.read_csv('./bengaliai_cv19/class_map.csv')\n",
    "sample_sub_df = pd.read_csv('./bengaliai_cv19/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_path = './bengaliai_cv19/train_128_0/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridMask & Augmix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2020\n",
    "batch_size = 12 \n",
    "# dim, size는 64x64 라서 64로 수정\n",
    "dim = (128, 128)\n",
    "SIZE = 128\n",
    "stats = (0.0692, 0.2051)\n",
    "HEIGHT = 137 \n",
    "WIDTH = 236\n",
    "\n",
    "import random\n",
    "def seed_all(SEED):\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "    \n",
    "# seed all\n",
    "seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import albumentations\n",
    "from albumentations.core.transforms_interface import DualTransform\n",
    "from albumentations.augmentations import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "\n",
    "## Grid Mask\n",
    "# code takesn from https://www.kaggle.com/haqishen/gridmask\n",
    "\n",
    "import albumentations\n",
    "from albumentations.core.transforms_interface import DualTransform, ImageOnlyTransform\n",
    "from albumentations.augmentations import functional as F\n",
    "\n",
    "class GridMask(DualTransform):\n",
    "    \"\"\"GridMask augmentation for image classification and object detection.\n",
    "\n",
    "    Args:\n",
    "        num_grid (int): number of grid in a row or column.\n",
    "        fill_value (int, float, lisf of int, list of float): value for dropped pixels.\n",
    "        rotate ((int, int) or int): range from which a random angle is picked. If rotate is a single int\n",
    "            an angle is picked from (-rotate, rotate). Default: (-90, 90)\n",
    "        mode (int):\n",
    "            0 - cropout a quarter of the square of each grid (left top)\n",
    "            1 - reserve a quarter of the square of each grid (left top)\n",
    "            2 - cropout 2 quarter of the square of each grid (left top & right bottom)\n",
    "\n",
    "    Targets:\n",
    "        image, mask\n",
    "\n",
    "    Image types:\n",
    "        uint8, float32\n",
    "\n",
    "    Reference:\n",
    "    |  https://arxiv.org/abs/2001.04086\n",
    "    |  https://github.com/akuxcw/GridMask\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_grid=3, fill_value=0, rotate=0, mode=0, always_apply=False, p=0.5):\n",
    "        super(GridMask, self).__init__(always_apply, p)\n",
    "        if isinstance(num_grid, int):\n",
    "            num_grid = (num_grid, num_grid)\n",
    "        if isinstance(rotate, int):\n",
    "            rotate = (-rotate, rotate)\n",
    "        self.num_grid = num_grid\n",
    "        self.fill_value = fill_value\n",
    "        self.rotate = rotate\n",
    "        self.mode = mode\n",
    "        self.masks = None\n",
    "        self.rand_h_max = []\n",
    "        self.rand_w_max = []\n",
    "\n",
    "    def init_masks(self, height, width):\n",
    "        if self.masks is None:\n",
    "            self.masks = []\n",
    "            n_masks = self.num_grid[1] - self.num_grid[0] + 1\n",
    "            for n, n_g in enumerate(range(self.num_grid[0], self.num_grid[1] + 1, 1)):\n",
    "                grid_h = height / n_g\n",
    "                grid_w = width / n_g\n",
    "                this_mask = np.ones((int((n_g + 1) * grid_h), int((n_g + 1) * grid_w))).astype(np.uint8)\n",
    "                for i in range(n_g + 1):\n",
    "                    for j in range(n_g + 1):\n",
    "                        this_mask[\n",
    "                             int(i * grid_h) : int(i * grid_h + grid_h / 2),\n",
    "                             int(j * grid_w) : int(j * grid_w + grid_w / 2)\n",
    "                        ] = self.fill_value\n",
    "                        if self.mode == 2:\n",
    "                            this_mask[\n",
    "                                 int(i * grid_h + grid_h / 2) : int(i * grid_h + grid_h),\n",
    "                                 int(j * grid_w + grid_w / 2) : int(j * grid_w + grid_w)\n",
    "                            ] = self.fill_value\n",
    "                \n",
    "                if self.mode == 1:\n",
    "                    this_mask = 1 - this_mask\n",
    "\n",
    "                self.masks.append(this_mask)\n",
    "                self.rand_h_max.append(grid_h)\n",
    "                self.rand_w_max.append(grid_w)\n",
    "\n",
    "    def apply(self, image, mask, rand_h, rand_w, angle, **params):\n",
    "        h, w = image.shape[:2]\n",
    "        mask = F.rotate(mask, angle) if self.rotate[1] > 0 else mask\n",
    "        mask = mask[:,:,np.newaxis] if image.ndim == 3 else mask\n",
    "        image *= mask[rand_h:rand_h+h, rand_w:rand_w+w].astype(image.dtype)\n",
    "        return image\n",
    "\n",
    "    def get_params_dependent_on_targets(self, params):\n",
    "        img = params['image']\n",
    "        height, width = img.shape[:2]\n",
    "        self.init_masks(height, width)\n",
    "\n",
    "        mid = np.random.randint(len(self.masks))\n",
    "        mask = self.masks[mid]\n",
    "        rand_h = np.random.randint(self.rand_h_max[mid])\n",
    "        rand_w = np.random.randint(self.rand_w_max[mid])\n",
    "        angle = np.random.randint(self.rotate[0], self.rotate[1]) if self.rotate[1] > 0 else 0\n",
    "\n",
    "        return {'mask': mask, 'rand_h': rand_h, 'rand_w': rand_w, 'angle': angle}\n",
    "\n",
    "    @property\n",
    "    def targets_as_params(self):\n",
    "        return ['image']\n",
    "\n",
    "    def get_transform_init_args_names(self):\n",
    "        return ('num_grid', 'fill_value', 'rotate', 'mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmix : https://github.com/google-research/augmix\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "import numpy as np\n",
    "\n",
    "def int_parameter(level, maxval):\n",
    "    \"\"\"Helper function to scale `val` between 0 and maxval .\n",
    "    Args:\n",
    "    level: Level of the operation that will be between [0, `PARAMETER_MAX`].\n",
    "    maxval: Maximum value that the operation can have. This will be scaled to\n",
    "      level/PARAMETER_MAX.\n",
    "    Returns:\n",
    "    An int that results from scaling `maxval` according to `level`.\n",
    "    \"\"\"\n",
    "    return int(level * maxval / 10)\n",
    "\n",
    "\n",
    "def float_parameter(level, maxval):\n",
    "    \"\"\"Helper function to scale `val` between 0 and maxval.\n",
    "    Args:\n",
    "    level: Level of the operation that will be between [0, `PARAMETER_MAX`].\n",
    "    maxval: Maximum value that the operation can have. This will be scaled to\n",
    "      level/PARAMETER_MAX.\n",
    "    Returns:\n",
    "    A float that results from scaling `maxval` according to `level`.\n",
    "    \"\"\"\n",
    "    return float(level) * maxval / 10.\n",
    "\n",
    "def sample_level(n):\n",
    "    return np.random.uniform(low=0.1, high=n)\n",
    "\n",
    "def autocontrast(pil_img, _):\n",
    "    return ImageOps.autocontrast(pil_img)\n",
    "\n",
    "def equalize(pil_img, _):\n",
    "    return ImageOps.equalize(pil_img)\n",
    "\n",
    "def posterize(pil_img, level):\n",
    "    level = int_parameter(sample_level(level), 4)\n",
    "    return ImageOps.posterize(pil_img, 4 - level)\n",
    "\n",
    "def rotate(pil_img, level):\n",
    "    degrees = int_parameter(sample_level(level), 30)\n",
    "    if np.random.uniform() > 0.5:\n",
    "        degrees = -degrees\n",
    "    return pil_img.rotate(degrees, resample=Image.BILINEAR)\n",
    "\n",
    "def solarize(pil_img, level):\n",
    "    level = int_parameter(sample_level(level), 256)\n",
    "    return ImageOps.solarize(pil_img, 256 - level)\n",
    "\n",
    "def shear_x(pil_img, level):\n",
    "    level = float_parameter(sample_level(level), 0.3)\n",
    "    if np.random.uniform() > 0.5:\n",
    "        level = -level\n",
    "    return pil_img.transform((SIZE, SIZE),\n",
    "                           Image.AFFINE, (1, level, 0, 0, 1, 0),\n",
    "                           resample=Image.BILINEAR)\n",
    "\n",
    "def shear_y(pil_img, level):\n",
    "    level = float_parameter(sample_level(level), 0.3)\n",
    "    if np.random.uniform() > 0.5:\n",
    "        level = -level\n",
    "    return pil_img.transform((SIZE, SIZE),\n",
    "                           Image.AFFINE, (1, 0, 0, level, 1, 0),\n",
    "                           resample=Image.BILINEAR)\n",
    "\n",
    "def translate_x(pil_img, level):\n",
    "    level = int_parameter(sample_level(level), SIZE / 3)\n",
    "    if np.random.random() > 0.5:\n",
    "        level = -level\n",
    "    return pil_img.transform((SIZE, SIZE),\n",
    "                           Image.AFFINE, (1, 0, level, 0, 1, 0),\n",
    "                           resample=Image.BILINEAR)\n",
    "\n",
    "\n",
    "def translate_y(pil_img, level):\n",
    "    level = int_parameter(sample_level(level), SIZE / 3)\n",
    "    if np.random.random() > 0.5:\n",
    "        level = -level\n",
    "    return pil_img.transform((SIZE, SIZE),\n",
    "                           Image.AFFINE, (1, 0, 0, 0, 1, level),\n",
    "                           resample=Image.BILINEAR)\n",
    "\n",
    "augmentations = [\n",
    "    autocontrast, equalize, posterize, rotate, solarize, shear_x, shear_y,\n",
    "    translate_x, translate_y\n",
    "]\n",
    "\n",
    "# taken from https://www.kaggle.com/iafoss/image-preprocessing-128x128\n",
    "MEAN = [ 0.06922848809290576,  0.06922848809290576,  0.06922848809290576]\n",
    "STD = [ 0.20515700083327537,  0.20515700083327537,  0.20515700083327537]\n",
    "\n",
    "def normalize(image):\n",
    "    \"\"\"Normalize input image channel-wise to zero mean and unit variance.\"\"\"\n",
    "    image = image.transpose(2, 0, 1)  # Switch to channel-first\n",
    "    mean, std = np.array(MEAN), np.array(STD)\n",
    "    image = (image - mean[:, None, None]) / std[:, None, None]\n",
    "    return image.transpose(1, 2, 0)\n",
    "\n",
    "\n",
    "def apply_op(image, op, severity):\n",
    "    image = np.clip(image * 255., 0, 255).astype(np.uint8)\n",
    "    pil_img = Image.fromarray(image)  # Convert to PIL.Image\n",
    "    pil_img = op(pil_img, severity)\n",
    "    return np.asarray(pil_img) / 255.\n",
    "\n",
    "\n",
    "def augment_and_mix(image, severity=1, width=3, depth=1, alpha=1.):\n",
    "    \"\"\"Perform AugMix augmentations and compute mixture.\n",
    "    Args:\n",
    "    image: Raw input image as float32 np.ndarray of shape (h, w, c)\n",
    "    severity: Severity of underlying augmentation operators (between 1 to 10).\n",
    "    width: Width of augmentation chain\n",
    "    depth: Depth of augmentation chain. -1 enables stochastic depth uniformly\n",
    "      from [1, 3]\n",
    "    alpha: Probability coefficient for Beta and Dirichlet distributions.\n",
    "    Returns:\n",
    "    mixed: Augmented and mixed image.\n",
    "  \"\"\"\n",
    "    ws = np.float32(\n",
    "      np.random.dirichlet([alpha] * width))\n",
    "    m = np.float32(np.random.beta(alpha, alpha))\n",
    "\n",
    "    mix = np.zeros_like(image)\n",
    "    for i in range(width):\n",
    "        image_aug = image.copy()\n",
    "        depth = depth if depth > 0 else np.random.randint(1, 4)\n",
    "        \n",
    "        for _ in range(depth):\n",
    "            op = np.random.choice(augmentations)\n",
    "            image_aug = apply_op(image_aug, op, severity)\n",
    "        mix = np.add(mix, ws[i] * normalize(image_aug), out=mix, \n",
    "                     casting=\"unsafe\")\n",
    "\n",
    "    mixed = (1 - m) * normalize(image) + m * mix\n",
    "    return mixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 임시 데이터 생성 ( train에서 msss 쓰기 위해)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Image Size Summary\\nprint(HEIGHT_NEW)\\nprint(WIDTH_NEW)\\n\\n# Generate Image (Has to be done only one time .. or again when changing SCALE_FACTOR)\\n\\nGENERATE_IMAGES = True\\nif GENERATE_IMAGES:\\n    generate_images(DATA_DIR, TRAIN_DIR, WIDTH, HEIGHT, IMG_SIZE, IMG_SIZE)\\n\\n# Prepare Train Labels (Y)\\ntrain_df = pd.read_csv('./bengaliai_cv19/train.csv')\\ntgt_cols = ['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']\\ndesc_df = train_df[tgt_cols].astype('str').describe()\\ntypes = desc_df.loc['unique',:]\\nX_train = train_df['image_id'].values\\ntrain_df = train_df[tgt_cols].astype('uint8')\\nfor col in tgt_cols:\\n    train_df[col] = train_df[col].map('{:03}'.format)\\nY_train = pd.get_dummies(train_df)\\n\\n# Cleanup\\ndel train_df\\ngc.collect()\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_SIZE = 128\n",
    "HEIGHT = 137\n",
    "WIDTH = 236\n",
    "FACTOR = 0.70\n",
    "CHANNELS = 3\n",
    "BATCH_SIZE = 56\n",
    "TEST_SIZE = 1./6\n",
    "\n",
    "# Dir\n",
    "# Input Dir\n",
    "DATA_DIR = './bengaliai_cv19/'     #'C:/KaggleBengaliAI/bengaliai-cv19'\n",
    "TRAIN_DIR = './train/'         #'./train/'\n",
    "\n",
    "# Constants\n",
    "RUN_NAME = 'Train1_'\n",
    "PLOT_NAME1 = 'Train1_LossAndAccuracy.png'\n",
    "PLOT_NAME2 = 'Train1_Recall.png'\n",
    "\n",
    "\n",
    "'''\n",
    "# Image Size Summary\n",
    "print(HEIGHT_NEW)\n",
    "print(WIDTH_NEW)\n",
    "\n",
    "# Generate Image (Has to be done only one time .. or again when changing SCALE_FACTOR)\n",
    "''''''\n",
    "GENERATE_IMAGES = True\n",
    "if GENERATE_IMAGES:\n",
    "    generate_images(DATA_DIR, TRAIN_DIR, WIDTH, HEIGHT, IMG_SIZE, IMG_SIZE)\n",
    "\n",
    "# Prepare Train Labels (Y)\n",
    "train_df = pd.read_csv('./bengaliai_cv19/train.csv')\n",
    "tgt_cols = ['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']\n",
    "desc_df = train_df[tgt_cols].astype('str').describe()\n",
    "types = desc_df.loc['unique',:]\n",
    "X_train = train_df['image_id'].values\n",
    "train_df = train_df[tgt_cols].astype('uint8')\n",
    "for col in tgt_cols:\n",
    "    train_df[col] = train_df[col].map('{:03}'.format)\n",
    "Y_train = pd.get_dummies(train_df)\n",
    "\n",
    "# Cleanup\n",
    "del train_df\n",
    "gc.collect()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generalized mean pool - GeM\n",
    "gm_exp = tf.Variable(3.0, dtype = tf.float32)\n",
    "def generalized_mean_pool_2d(X):\n",
    "    pool = (tf.reduce_mean(tf.abs(X**(gm_exp)), \n",
    "                        axis = [1, 2], \n",
    "                        keepdims = False) + 1.e-7)**(1./gm_exp)\n",
    "    return pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model\n",
    "def create_model(input_shape):\n",
    "    # Input Layer\n",
    "    input = Input(shape = input_shape)\n",
    "    \n",
    "    # Create and Compile Model and show Summary\n",
    "    x_model = efn.EfficientNetB3(weights = None, include_top = False, input_tensor = input, pooling = None, classes = None)\n",
    "    \n",
    "    # UnFreeze all layers\n",
    "    for layer in x_model.layers:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    # GeM\n",
    "    lambda_layer = Lambda(generalized_mean_pool_2d)\n",
    "    lambda_layer.trainable_weights.extend([gm_exp])\n",
    "    x = lambda_layer(x_model.output)\n",
    "    \n",
    "    # multi output\n",
    "    grapheme_root = Dense(168, activation = 'softmax', name = 'root')(x)\n",
    "    vowel_diacritic = Dense(11, activation = 'softmax', name = 'vowel')(x)\n",
    "    consonant_diacritic = Dense(7, activation = 'softmax', name = 'consonant')(x)\n",
    "\n",
    "    # model\n",
    "    model = Model(inputs = x_model.input, outputs = [grapheme_root, vowel_diacritic, consonant_diacritic])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_model\n",
    "model = create_model(input_shape = (IMG_SIZE, IMG_SIZE, CHANNELS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "\n",
    "model.compile(optimizer = Adam(lr = 0.00016),\n",
    "                loss = {'root': 'categorical_crossentropy',\n",
    "                        'vowel': 'categorical_crossentropy',\n",
    "                        'consonant': 'categorical_crossentropy'},\n",
    "                loss_weights = {'root': 0.40,        \n",
    "                                'vowel': 0.30,\n",
    "                                'consonant': 0.30},\n",
    "                metrics = {'root': ['accuracy', tf.keras.metrics.Recall()],\n",
    "                            'vowel': ['accuracy', tf.keras.metrics.Recall()],\n",
    "                            'consonant': ['accuracy', tf.keras.metrics.Recall()] })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv (Conv2D)              (None, 64, 64, 40)   1080        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "stem_bn (BatchNormalization)    (None, 64, 64, 40)   160         stem_conv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "stem_activation (Activation)    (None, 64, 64, 40)   0           stem_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1a_dwconv (DepthwiseConv2D (None, 64, 64, 40)   360         stem_activation[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1a_bn (BatchNormalization) (None, 64, 64, 40)   160         block1a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1a_activation (Activation) (None, 64, 64, 40)   0           block1a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_squeeze (GlobalAvera (None, 40)           0           block1a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reshape (Reshape)    (None, 1, 1, 40)     0           block1a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reduce (Conv2D)      (None, 1, 1, 10)     410         block1a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_expand (Conv2D)      (None, 1, 1, 40)     440         block1a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_excite (Multiply)    (None, 64, 64, 40)   0           block1a_activation[0][0]         \n",
      "                                                                 block1a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_conv (Conv2D)   (None, 64, 64, 24)   960         block1a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_bn (BatchNormal (None, 64, 64, 24)   96          block1a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1b_dwconv (DepthwiseConv2D (None, 64, 64, 24)   216         block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_bn (BatchNormalization) (None, 64, 64, 24)   96          block1b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1b_activation (Activation) (None, 64, 64, 24)   0           block1b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_squeeze (GlobalAvera (None, 24)           0           block1b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_reshape (Reshape)    (None, 1, 1, 24)     0           block1b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_reduce (Conv2D)      (None, 1, 1, 6)      150         block1b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_expand (Conv2D)      (None, 1, 1, 24)     168         block1b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_excite (Multiply)    (None, 64, 64, 24)   0           block1b_activation[0][0]         \n",
      "                                                                 block1b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_project_conv (Conv2D)   (None, 64, 64, 24)   576         block1b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_project_bn (BatchNormal (None, 64, 64, 24)   96          block1b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1b_drop (FixedDropout)     (None, 64, 64, 24)   0           block1b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_add (Add)               (None, 64, 64, 24)   0           block1b_drop[0][0]               \n",
      "                                                                 block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_conv (Conv2D)    (None, 64, 64, 144)  3456        block1b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_bn (BatchNormali (None, 64, 64, 144)  576         block2a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_activation (Acti (None, 64, 64, 144)  0           block2a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv (DepthwiseConv2D (None, 32, 32, 144)  1296        block2a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2a_bn (BatchNormalization) (None, 32, 32, 144)  576         block2a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2a_activation (Activation) (None, 32, 32, 144)  0           block2a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_squeeze (GlobalAvera (None, 144)          0           block2a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reshape (Reshape)    (None, 1, 1, 144)    0           block2a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block2a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block2a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_excite (Multiply)    (None, 32, 32, 144)  0           block2a_activation[0][0]         \n",
      "                                                                 block2a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_conv (Conv2D)   (None, 32, 32, 32)   4608        block2a_se_excite[0][0]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "block2a_project_bn (BatchNormal (None, 32, 32, 32)   128         block2a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_conv (Conv2D)    (None, 32, 32, 192)  6144        block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_bn (BatchNormali (None, 32, 32, 192)  768         block2b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_activation (Acti (None, 32, 32, 192)  0           block2b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_dwconv (DepthwiseConv2D (None, 32, 32, 192)  1728        block2b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2b_bn (BatchNormalization) (None, 32, 32, 192)  768         block2b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2b_activation (Activation) (None, 32, 32, 192)  0           block2b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_squeeze (GlobalAvera (None, 192)          0           block2b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reshape (Reshape)    (None, 1, 1, 192)    0           block2b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reduce (Conv2D)      (None, 1, 1, 8)      1544        block2b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_expand (Conv2D)      (None, 1, 1, 192)    1728        block2b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_excite (Multiply)    (None, 32, 32, 192)  0           block2b_activation[0][0]         \n",
      "                                                                 block2b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_conv (Conv2D)   (None, 32, 32, 32)   6144        block2b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_bn (BatchNormal (None, 32, 32, 32)   128         block2b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_drop (FixedDropout)     (None, 32, 32, 32)   0           block2b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_add (Add)               (None, 32, 32, 32)   0           block2b_drop[0][0]               \n",
      "                                                                 block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_conv (Conv2D)    (None, 32, 32, 192)  6144        block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_bn (BatchNormali (None, 32, 32, 192)  768         block2c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_activation (Acti (None, 32, 32, 192)  0           block2c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_dwconv (DepthwiseConv2D (None, 32, 32, 192)  1728        block2c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2c_bn (BatchNormalization) (None, 32, 32, 192)  768         block2c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2c_activation (Activation) (None, 32, 32, 192)  0           block2c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_squeeze (GlobalAvera (None, 192)          0           block2c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_reshape (Reshape)    (None, 1, 1, 192)    0           block2c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_reduce (Conv2D)      (None, 1, 1, 8)      1544        block2c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_expand (Conv2D)      (None, 1, 1, 192)    1728        block2c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_excite (Multiply)    (None, 32, 32, 192)  0           block2c_activation[0][0]         \n",
      "                                                                 block2c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_project_conv (Conv2D)   (None, 32, 32, 32)   6144        block2c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_project_bn (BatchNormal (None, 32, 32, 32)   128         block2c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2c_drop (FixedDropout)     (None, 32, 32, 32)   0           block2c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_add (Add)               (None, 32, 32, 32)   0           block2c_drop[0][0]               \n",
      "                                                                 block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_conv (Conv2D)    (None, 32, 32, 192)  6144        block2c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_bn (BatchNormali (None, 32, 32, 192)  768         block3a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_activation (Acti (None, 32, 32, 192)  0           block3a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv (DepthwiseConv2D (None, 16, 16, 192)  4800        block3a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3a_bn (BatchNormalization) (None, 16, 16, 192)  768         block3a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3a_activation (Activation) (None, 16, 16, 192)  0           block3a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_squeeze (GlobalAvera (None, 192)          0           block3a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reshape (Reshape)    (None, 1, 1, 192)    0           block3a_se_squeeze[0][0]         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "block3a_se_reduce (Conv2D)      (None, 1, 1, 8)      1544        block3a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_expand (Conv2D)      (None, 1, 1, 192)    1728        block3a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_excite (Multiply)    (None, 16, 16, 192)  0           block3a_activation[0][0]         \n",
      "                                                                 block3a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_conv (Conv2D)   (None, 16, 16, 48)   9216        block3a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_bn (BatchNormal (None, 16, 16, 48)   192         block3a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_conv (Conv2D)    (None, 16, 16, 288)  13824       block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_bn (BatchNormali (None, 16, 16, 288)  1152        block3b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_activation (Acti (None, 16, 16, 288)  0           block3b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_dwconv (DepthwiseConv2D (None, 16, 16, 288)  7200        block3b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3b_bn (BatchNormalization) (None, 16, 16, 288)  1152        block3b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3b_activation (Activation) (None, 16, 16, 288)  0           block3b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_squeeze (GlobalAvera (None, 288)          0           block3b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reshape (Reshape)    (None, 1, 1, 288)    0           block3b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block3b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block3b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_excite (Multiply)    (None, 16, 16, 288)  0           block3b_activation[0][0]         \n",
      "                                                                 block3b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_conv (Conv2D)   (None, 16, 16, 48)   13824       block3b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_bn (BatchNormal (None, 16, 16, 48)   192         block3b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_drop (FixedDropout)     (None, 16, 16, 48)   0           block3b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_add (Add)               (None, 16, 16, 48)   0           block3b_drop[0][0]               \n",
      "                                                                 block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_conv (Conv2D)    (None, 16, 16, 288)  13824       block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_bn (BatchNormali (None, 16, 16, 288)  1152        block3c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_activation (Acti (None, 16, 16, 288)  0           block3c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_dwconv (DepthwiseConv2D (None, 16, 16, 288)  7200        block3c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3c_bn (BatchNormalization) (None, 16, 16, 288)  1152        block3c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3c_activation (Activation) (None, 16, 16, 288)  0           block3c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_squeeze (GlobalAvera (None, 288)          0           block3c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_reshape (Reshape)    (None, 1, 1, 288)    0           block3c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block3c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block3c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_excite (Multiply)    (None, 16, 16, 288)  0           block3c_activation[0][0]         \n",
      "                                                                 block3c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_project_conv (Conv2D)   (None, 16, 16, 48)   13824       block3c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_project_bn (BatchNormal (None, 16, 16, 48)   192         block3c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3c_drop (FixedDropout)     (None, 16, 16, 48)   0           block3c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_add (Add)               (None, 16, 16, 48)   0           block3c_drop[0][0]               \n",
      "                                                                 block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_conv (Conv2D)    (None, 16, 16, 288)  13824       block3c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_bn (BatchNormali (None, 16, 16, 288)  1152        block4a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_activation (Acti (None, 16, 16, 288)  0           block4a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block4a_dwconv (DepthwiseConv2D (None, 8, 8, 288)    2592        block4a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4a_bn (BatchNormalization) (None, 8, 8, 288)    1152        block4a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4a_activation (Activation) (None, 8, 8, 288)    0           block4a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_squeeze (GlobalAvera (None, 288)          0           block4a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reshape (Reshape)    (None, 1, 1, 288)    0           block4a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block4a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block4a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_excite (Multiply)    (None, 8, 8, 288)    0           block4a_activation[0][0]         \n",
      "                                                                 block4a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_conv (Conv2D)   (None, 8, 8, 96)     27648       block4a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_bn (BatchNormal (None, 8, 8, 96)     384         block4a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_conv (Conv2D)    (None, 8, 8, 576)    55296       block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_bn (BatchNormali (None, 8, 8, 576)    2304        block4b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_activation (Acti (None, 8, 8, 576)    0           block4b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_dwconv (DepthwiseConv2D (None, 8, 8, 576)    5184        block4b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4b_bn (BatchNormalization) (None, 8, 8, 576)    2304        block4b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4b_activation (Activation) (None, 8, 8, 576)    0           block4b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_squeeze (GlobalAvera (None, 576)          0           block4b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reshape (Reshape)    (None, 1, 1, 576)    0           block4b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reduce (Conv2D)      (None, 1, 1, 24)     13848       block4b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_expand (Conv2D)      (None, 1, 1, 576)    14400       block4b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_excite (Multiply)    (None, 8, 8, 576)    0           block4b_activation[0][0]         \n",
      "                                                                 block4b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_conv (Conv2D)   (None, 8, 8, 96)     55296       block4b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_bn (BatchNormal (None, 8, 8, 96)     384         block4b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_drop (FixedDropout)     (None, 8, 8, 96)     0           block4b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_add (Add)               (None, 8, 8, 96)     0           block4b_drop[0][0]               \n",
      "                                                                 block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_conv (Conv2D)    (None, 8, 8, 576)    55296       block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_bn (BatchNormali (None, 8, 8, 576)    2304        block4c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_activation (Acti (None, 8, 8, 576)    0           block4c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_dwconv (DepthwiseConv2D (None, 8, 8, 576)    5184        block4c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4c_bn (BatchNormalization) (None, 8, 8, 576)    2304        block4c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4c_activation (Activation) (None, 8, 8, 576)    0           block4c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_squeeze (GlobalAvera (None, 576)          0           block4c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reshape (Reshape)    (None, 1, 1, 576)    0           block4c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reduce (Conv2D)      (None, 1, 1, 24)     13848       block4c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_expand (Conv2D)      (None, 1, 1, 576)    14400       block4c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_excite (Multiply)    (None, 8, 8, 576)    0           block4c_activation[0][0]         \n",
      "                                                                 block4c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_conv (Conv2D)   (None, 8, 8, 96)     55296       block4c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_bn (BatchNormal (None, 8, 8, 96)     384         block4c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4c_drop (FixedDropout)     (None, 8, 8, 96)     0           block4c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block4c_add (Add)               (None, 8, 8, 96)     0           block4c_drop[0][0]               \n",
      "                                                                 block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_conv (Conv2D)    (None, 8, 8, 576)    55296       block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_bn (BatchNormali (None, 8, 8, 576)    2304        block4d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_activation (Acti (None, 8, 8, 576)    0           block4d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_dwconv (DepthwiseConv2D (None, 8, 8, 576)    5184        block4d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4d_bn (BatchNormalization) (None, 8, 8, 576)    2304        block4d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4d_activation (Activation) (None, 8, 8, 576)    0           block4d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_squeeze (GlobalAvera (None, 576)          0           block4d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_reshape (Reshape)    (None, 1, 1, 576)    0           block4d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_reduce (Conv2D)      (None, 1, 1, 24)     13848       block4d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_expand (Conv2D)      (None, 1, 1, 576)    14400       block4d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_excite (Multiply)    (None, 8, 8, 576)    0           block4d_activation[0][0]         \n",
      "                                                                 block4d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_project_conv (Conv2D)   (None, 8, 8, 96)     55296       block4d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_project_bn (BatchNormal (None, 8, 8, 96)     384         block4d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4d_drop (FixedDropout)     (None, 8, 8, 96)     0           block4d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_add (Add)               (None, 8, 8, 96)     0           block4d_drop[0][0]               \n",
      "                                                                 block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_conv (Conv2D)    (None, 8, 8, 576)    55296       block4d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_bn (BatchNormali (None, 8, 8, 576)    2304        block4e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_activation (Acti (None, 8, 8, 576)    0           block4e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_dwconv (DepthwiseConv2D (None, 8, 8, 576)    5184        block4e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4e_bn (BatchNormalization) (None, 8, 8, 576)    2304        block4e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4e_activation (Activation) (None, 8, 8, 576)    0           block4e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_squeeze (GlobalAvera (None, 576)          0           block4e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_reshape (Reshape)    (None, 1, 1, 576)    0           block4e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_reduce (Conv2D)      (None, 1, 1, 24)     13848       block4e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_expand (Conv2D)      (None, 1, 1, 576)    14400       block4e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_excite (Multiply)    (None, 8, 8, 576)    0           block4e_activation[0][0]         \n",
      "                                                                 block4e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_project_conv (Conv2D)   (None, 8, 8, 96)     55296       block4e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_project_bn (BatchNormal (None, 8, 8, 96)     384         block4e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4e_drop (FixedDropout)     (None, 8, 8, 96)     0           block4e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_add (Add)               (None, 8, 8, 96)     0           block4e_drop[0][0]               \n",
      "                                                                 block4d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_conv (Conv2D)    (None, 8, 8, 576)    55296       block4e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_bn (BatchNormali (None, 8, 8, 576)    2304        block5a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_activation (Acti (None, 8, 8, 576)    0           block5a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_dwconv (DepthwiseConv2D (None, 8, 8, 576)    14400       block5a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5a_bn (BatchNormalization) (None, 8, 8, 576)    2304        block5a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5a_activation (Activation) (None, 8, 8, 576)    0           block5a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_squeeze (GlobalAvera (None, 576)          0           block5a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reshape (Reshape)    (None, 1, 1, 576)    0           block5a_se_squeeze[0][0]         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "block5a_se_reduce (Conv2D)      (None, 1, 1, 24)     13848       block5a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_expand (Conv2D)      (None, 1, 1, 576)    14400       block5a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_excite (Multiply)    (None, 8, 8, 576)    0           block5a_activation[0][0]         \n",
      "                                                                 block5a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_conv (Conv2D)   (None, 8, 8, 136)    78336       block5a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_bn (BatchNormal (None, 8, 8, 136)    544         block5a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_conv (Conv2D)    (None, 8, 8, 816)    110976      block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_bn (BatchNormali (None, 8, 8, 816)    3264        block5b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_activation (Acti (None, 8, 8, 816)    0           block5b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_dwconv (DepthwiseConv2D (None, 8, 8, 816)    20400       block5b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5b_bn (BatchNormalization) (None, 8, 8, 816)    3264        block5b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5b_activation (Activation) (None, 8, 8, 816)    0           block5b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_squeeze (GlobalAvera (None, 816)          0           block5b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reshape (Reshape)    (None, 1, 1, 816)    0           block5b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reduce (Conv2D)      (None, 1, 1, 34)     27778       block5b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_expand (Conv2D)      (None, 1, 1, 816)    28560       block5b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_excite (Multiply)    (None, 8, 8, 816)    0           block5b_activation[0][0]         \n",
      "                                                                 block5b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_conv (Conv2D)   (None, 8, 8, 136)    110976      block5b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_bn (BatchNormal (None, 8, 8, 136)    544         block5b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_drop (FixedDropout)     (None, 8, 8, 136)    0           block5b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_add (Add)               (None, 8, 8, 136)    0           block5b_drop[0][0]               \n",
      "                                                                 block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_conv (Conv2D)    (None, 8, 8, 816)    110976      block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_bn (BatchNormali (None, 8, 8, 816)    3264        block5c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_activation (Acti (None, 8, 8, 816)    0           block5c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_dwconv (DepthwiseConv2D (None, 8, 8, 816)    20400       block5c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5c_bn (BatchNormalization) (None, 8, 8, 816)    3264        block5c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5c_activation (Activation) (None, 8, 8, 816)    0           block5c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_squeeze (GlobalAvera (None, 816)          0           block5c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reshape (Reshape)    (None, 1, 1, 816)    0           block5c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reduce (Conv2D)      (None, 1, 1, 34)     27778       block5c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_expand (Conv2D)      (None, 1, 1, 816)    28560       block5c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_excite (Multiply)    (None, 8, 8, 816)    0           block5c_activation[0][0]         \n",
      "                                                                 block5c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_conv (Conv2D)   (None, 8, 8, 136)    110976      block5c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_bn (BatchNormal (None, 8, 8, 136)    544         block5c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5c_drop (FixedDropout)     (None, 8, 8, 136)    0           block5c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_add (Add)               (None, 8, 8, 136)    0           block5c_drop[0][0]               \n",
      "                                                                 block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_conv (Conv2D)    (None, 8, 8, 816)    110976      block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_bn (BatchNormali (None, 8, 8, 816)    3264        block5d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_activation (Acti (None, 8, 8, 816)    0           block5d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block5d_dwconv (DepthwiseConv2D (None, 8, 8, 816)    20400       block5d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5d_bn (BatchNormalization) (None, 8, 8, 816)    3264        block5d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5d_activation (Activation) (None, 8, 8, 816)    0           block5d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_squeeze (GlobalAvera (None, 816)          0           block5d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_reshape (Reshape)    (None, 1, 1, 816)    0           block5d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_reduce (Conv2D)      (None, 1, 1, 34)     27778       block5d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_expand (Conv2D)      (None, 1, 1, 816)    28560       block5d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_excite (Multiply)    (None, 8, 8, 816)    0           block5d_activation[0][0]         \n",
      "                                                                 block5d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_project_conv (Conv2D)   (None, 8, 8, 136)    110976      block5d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_project_bn (BatchNormal (None, 8, 8, 136)    544         block5d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5d_drop (FixedDropout)     (None, 8, 8, 136)    0           block5d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_add (Add)               (None, 8, 8, 136)    0           block5d_drop[0][0]               \n",
      "                                                                 block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_conv (Conv2D)    (None, 8, 8, 816)    110976      block5d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_bn (BatchNormali (None, 8, 8, 816)    3264        block5e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_activation (Acti (None, 8, 8, 816)    0           block5e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_dwconv (DepthwiseConv2D (None, 8, 8, 816)    20400       block5e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5e_bn (BatchNormalization) (None, 8, 8, 816)    3264        block5e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5e_activation (Activation) (None, 8, 8, 816)    0           block5e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_squeeze (GlobalAvera (None, 816)          0           block5e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_reshape (Reshape)    (None, 1, 1, 816)    0           block5e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_reduce (Conv2D)      (None, 1, 1, 34)     27778       block5e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_expand (Conv2D)      (None, 1, 1, 816)    28560       block5e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_excite (Multiply)    (None, 8, 8, 816)    0           block5e_activation[0][0]         \n",
      "                                                                 block5e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_project_conv (Conv2D)   (None, 8, 8, 136)    110976      block5e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_project_bn (BatchNormal (None, 8, 8, 136)    544         block5e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5e_drop (FixedDropout)     (None, 8, 8, 136)    0           block5e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_add (Add)               (None, 8, 8, 136)    0           block5e_drop[0][0]               \n",
      "                                                                 block5d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_conv (Conv2D)    (None, 8, 8, 816)    110976      block5e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_bn (BatchNormali (None, 8, 8, 816)    3264        block6a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_activation (Acti (None, 8, 8, 816)    0           block6a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv (DepthwiseConv2D (None, 4, 4, 816)    20400       block6a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6a_bn (BatchNormalization) (None, 4, 4, 816)    3264        block6a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6a_activation (Activation) (None, 4, 4, 816)    0           block6a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_squeeze (GlobalAvera (None, 816)          0           block6a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reshape (Reshape)    (None, 1, 1, 816)    0           block6a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reduce (Conv2D)      (None, 1, 1, 34)     27778       block6a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_expand (Conv2D)      (None, 1, 1, 816)    28560       block6a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_excite (Multiply)    (None, 4, 4, 816)    0           block6a_activation[0][0]         \n",
      "                                                                 block6a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_conv (Conv2D)   (None, 4, 4, 232)    189312      block6a_se_excite[0][0]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "block6a_project_bn (BatchNormal (None, 4, 4, 232)    928         block6a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_conv (Conv2D)    (None, 4, 4, 1392)   322944      block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_bn (BatchNormali (None, 4, 4, 1392)   5568        block6b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_activation (Acti (None, 4, 4, 1392)   0           block6b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_dwconv (DepthwiseConv2D (None, 4, 4, 1392)   34800       block6b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6b_bn (BatchNormalization) (None, 4, 4, 1392)   5568        block6b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6b_activation (Activation) (None, 4, 4, 1392)   0           block6b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_squeeze (GlobalAvera (None, 1392)         0           block6b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reshape (Reshape)    (None, 1, 1, 1392)   0           block6b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reduce (Conv2D)      (None, 1, 1, 58)     80794       block6b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_expand (Conv2D)      (None, 1, 1, 1392)   82128       block6b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_excite (Multiply)    (None, 4, 4, 1392)   0           block6b_activation[0][0]         \n",
      "                                                                 block6b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_conv (Conv2D)   (None, 4, 4, 232)    322944      block6b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_bn (BatchNormal (None, 4, 4, 232)    928         block6b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_drop (FixedDropout)     (None, 4, 4, 232)    0           block6b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_add (Add)               (None, 4, 4, 232)    0           block6b_drop[0][0]               \n",
      "                                                                 block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_conv (Conv2D)    (None, 4, 4, 1392)   322944      block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_bn (BatchNormali (None, 4, 4, 1392)   5568        block6c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_activation (Acti (None, 4, 4, 1392)   0           block6c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_dwconv (DepthwiseConv2D (None, 4, 4, 1392)   34800       block6c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6c_bn (BatchNormalization) (None, 4, 4, 1392)   5568        block6c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6c_activation (Activation) (None, 4, 4, 1392)   0           block6c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_squeeze (GlobalAvera (None, 1392)         0           block6c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reshape (Reshape)    (None, 1, 1, 1392)   0           block6c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reduce (Conv2D)      (None, 1, 1, 58)     80794       block6c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_expand (Conv2D)      (None, 1, 1, 1392)   82128       block6c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_excite (Multiply)    (None, 4, 4, 1392)   0           block6c_activation[0][0]         \n",
      "                                                                 block6c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_conv (Conv2D)   (None, 4, 4, 232)    322944      block6c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_bn (BatchNormal (None, 4, 4, 232)    928         block6c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6c_drop (FixedDropout)     (None, 4, 4, 232)    0           block6c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_add (Add)               (None, 4, 4, 232)    0           block6c_drop[0][0]               \n",
      "                                                                 block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_conv (Conv2D)    (None, 4, 4, 1392)   322944      block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_bn (BatchNormali (None, 4, 4, 1392)   5568        block6d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_activation (Acti (None, 4, 4, 1392)   0           block6d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_dwconv (DepthwiseConv2D (None, 4, 4, 1392)   34800       block6d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6d_bn (BatchNormalization) (None, 4, 4, 1392)   5568        block6d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6d_activation (Activation) (None, 4, 4, 1392)   0           block6d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_squeeze (GlobalAvera (None, 1392)         0           block6d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reshape (Reshape)    (None, 1, 1, 1392)   0           block6d_se_squeeze[0][0]         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "block6d_se_reduce (Conv2D)      (None, 1, 1, 58)     80794       block6d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_expand (Conv2D)      (None, 1, 1, 1392)   82128       block6d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_excite (Multiply)    (None, 4, 4, 1392)   0           block6d_activation[0][0]         \n",
      "                                                                 block6d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_conv (Conv2D)   (None, 4, 4, 232)    322944      block6d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_bn (BatchNormal (None, 4, 4, 232)    928         block6d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6d_drop (FixedDropout)     (None, 4, 4, 232)    0           block6d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_add (Add)               (None, 4, 4, 232)    0           block6d_drop[0][0]               \n",
      "                                                                 block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_conv (Conv2D)    (None, 4, 4, 1392)   322944      block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_bn (BatchNormali (None, 4, 4, 1392)   5568        block6e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_activation (Acti (None, 4, 4, 1392)   0           block6e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_dwconv (DepthwiseConv2D (None, 4, 4, 1392)   34800       block6e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6e_bn (BatchNormalization) (None, 4, 4, 1392)   5568        block6e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6e_activation (Activation) (None, 4, 4, 1392)   0           block6e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_squeeze (GlobalAvera (None, 1392)         0           block6e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_reshape (Reshape)    (None, 1, 1, 1392)   0           block6e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_reduce (Conv2D)      (None, 1, 1, 58)     80794       block6e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_expand (Conv2D)      (None, 1, 1, 1392)   82128       block6e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_excite (Multiply)    (None, 4, 4, 1392)   0           block6e_activation[0][0]         \n",
      "                                                                 block6e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_project_conv (Conv2D)   (None, 4, 4, 232)    322944      block6e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_project_bn (BatchNormal (None, 4, 4, 232)    928         block6e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6e_drop (FixedDropout)     (None, 4, 4, 232)    0           block6e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_add (Add)               (None, 4, 4, 232)    0           block6e_drop[0][0]               \n",
      "                                                                 block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_conv (Conv2D)    (None, 4, 4, 1392)   322944      block6e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_bn (BatchNormali (None, 4, 4, 1392)   5568        block6f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_activation (Acti (None, 4, 4, 1392)   0           block6f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_dwconv (DepthwiseConv2D (None, 4, 4, 1392)   34800       block6f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6f_bn (BatchNormalization) (None, 4, 4, 1392)   5568        block6f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6f_activation (Activation) (None, 4, 4, 1392)   0           block6f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_squeeze (GlobalAvera (None, 1392)         0           block6f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_reshape (Reshape)    (None, 1, 1, 1392)   0           block6f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_reduce (Conv2D)      (None, 1, 1, 58)     80794       block6f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_expand (Conv2D)      (None, 1, 1, 1392)   82128       block6f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_excite (Multiply)    (None, 4, 4, 1392)   0           block6f_activation[0][0]         \n",
      "                                                                 block6f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_project_conv (Conv2D)   (None, 4, 4, 232)    322944      block6f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_project_bn (BatchNormal (None, 4, 4, 232)    928         block6f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6f_drop (FixedDropout)     (None, 4, 4, 232)    0           block6f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_add (Add)               (None, 4, 4, 232)    0           block6f_drop[0][0]               \n",
      "                                                                 block6e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_conv (Conv2D)    (None, 4, 4, 1392)   322944      block6f_add[0][0]                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "block7a_expand_bn (BatchNormali (None, 4, 4, 1392)   5568        block7a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_activation (Acti (None, 4, 4, 1392)   0           block7a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_dwconv (DepthwiseConv2D (None, 4, 4, 1392)   12528       block7a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7a_bn (BatchNormalization) (None, 4, 4, 1392)   5568        block7a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7a_activation (Activation) (None, 4, 4, 1392)   0           block7a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_squeeze (GlobalAvera (None, 1392)         0           block7a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reshape (Reshape)    (None, 1, 1, 1392)   0           block7a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reduce (Conv2D)      (None, 1, 1, 58)     80794       block7a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_expand (Conv2D)      (None, 1, 1, 1392)   82128       block7a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_excite (Multiply)    (None, 4, 4, 1392)   0           block7a_activation[0][0]         \n",
      "                                                                 block7a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_conv (Conv2D)   (None, 4, 4, 384)    534528      block7a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_bn (BatchNormal (None, 4, 4, 384)    1536        block7a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_conv (Conv2D)    (None, 4, 4, 2304)   884736      block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_bn (BatchNormali (None, 4, 4, 2304)   9216        block7b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_activation (Acti (None, 4, 4, 2304)   0           block7b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_dwconv (DepthwiseConv2D (None, 4, 4, 2304)   20736       block7b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7b_bn (BatchNormalization) (None, 4, 4, 2304)   9216        block7b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7b_activation (Activation) (None, 4, 4, 2304)   0           block7b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_squeeze (GlobalAvera (None, 2304)         0           block7b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block7b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block7b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block7b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_excite (Multiply)    (None, 4, 4, 2304)   0           block7b_activation[0][0]         \n",
      "                                                                 block7b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_project_conv (Conv2D)   (None, 4, 4, 384)    884736      block7b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_project_bn (BatchNormal (None, 4, 4, 384)    1536        block7b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7b_drop (FixedDropout)     (None, 4, 4, 384)    0           block7b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_add (Add)               (None, 4, 4, 384)    0           block7b_drop[0][0]               \n",
      "                                                                 block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "top_conv (Conv2D)               (None, 4, 4, 1536)   589824      block7b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "top_bn (BatchNormalization)     (None, 4, 4, 1536)   6144        top_conv[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "top_activation (Activation)     (None, 4, 4, 1536)   0           top_bn[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1536)         0           top_activation[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "root (Dense)                    (None, 168)          258216      lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "vowel (Dense)                   (None, 11)           16907       lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "consonant (Dense)               (None, 7)            10759       lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 11,069,410\n",
      "Trainable params: 10,982,114\n",
      "Non-trainable params: 87,296\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Model Summary\n",
    "print(model.summary())\n",
    "\n",
    "# Multi Label Stratified Split stuff...\n",
    "epoch = 30\n",
    "msss = MultilabelStratifiedShuffleSplit(n_splits = epoch, test_size = TEST_SIZE, random_state = SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = np.Inf\n",
    "def CustomReduceLRonPlateau(model, history, epoch):\n",
    "    global best_val_loss\n",
    "    \n",
    "    # ReduceLR Constants\n",
    "    monitor = 'val_root_loss'\n",
    "    patience = 5\n",
    "    factor = 0.75\n",
    "    min_lr = 1e-5\n",
    "\n",
    "    # Get Current LR\n",
    "    current_lr = float(K.get_value(model.optimizer.lr))\n",
    "    \n",
    "    # Print Current Learning Rate\n",
    "    print('Current LR: {0}'.format(current_lr))\n",
    "\n",
    "    # Monitor Best Value\n",
    "    current_val_loss = history[monitor][-1]\n",
    "    if current_val_loss < best_val_loss:\n",
    "        best_val_loss = current_val_loss\n",
    "    print('Best Vall Loss: {0}'.format(best_val_loss))\n",
    "\n",
    "    # Track last values\n",
    "    if len(history[monitor]) >= patience:\n",
    "        last5 = history[monitor][-5:]\n",
    "        print('Last: {0}'.format(last5))\n",
    "        best_in_last = min(last5)\n",
    "        print('Min value in Last: {0}'.format(best_in_last))\n",
    "\n",
    "        # Determine correction\n",
    "        if best_val_loss < best_in_last:\n",
    "            new_lr = current_lr * factor\n",
    "            if new_lr < min_lr:\n",
    "                new_lr = min_lr\n",
    "            print('ReduceLRonPlateau setting learning rate to: {0}'.format(new_lr))\n",
    "            K.set_value(model.optimizer.lr, new_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ModelCheckpointFull(model_name):\n",
    "    return ModelCheckpoint(model_name, \n",
    "                            monitor = 'val_loss', \n",
    "                            verbose = 1, \n",
    "                            save_best_only = False, \n",
    "                            save_weights_only = True, \n",
    "                            mode = 'min', \n",
    "                            period = 1)\n",
    "\n",
    "\n",
    "def _read(path):\n",
    "    img = cv2.imread(path)    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grapheme Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphemeGenerator(Sequence):\n",
    "    def __init__(self, data, batch_size, dim, shuffle=True, transform=None):\n",
    "        self._data = data\n",
    "        self._label_1 = pd.get_dummies(self._data['grapheme_root'], \n",
    "                                       columns = ['grapheme_root'])\n",
    "        self._label_2 = pd.get_dummies(self._data['vowel_diacritic'], \n",
    "                                       columns = ['vowel_diacritic'])\n",
    "        self._label_3 = pd.get_dummies(self._data['consonant_diacritic'], \n",
    "                                       columns = ['consonant_diacritic'])\n",
    "        self._list_idx = data.index.values\n",
    "        self._batch_size = batch_size\n",
    "        self._dim = dim\n",
    "        self._shuffle = shuffle\n",
    "        self.transform = transform\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self._data)/self._batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_idx = self._indices[index*self._batch_size:(index+1)*self._batch_size]\n",
    "        _idx = [self._list_idx[k] for k in batch_idx]\n",
    "\n",
    "        Data     = np.empty((self._batch_size, *self._dim, 3))\n",
    "        Target_1 = np.empty((self._batch_size, 168), dtype = int)\n",
    "        Target_2 = np.empty((self._batch_size, 11 ), dtype = int)\n",
    "        Target_3 = np.empty((self._batch_size,  7 ), dtype = int)\n",
    "        \n",
    "        for i, k in enumerate(_idx):\n",
    "            # load the image file using cv2\n",
    "            image = cv2.imread(im_path + self._data['image_id'][k] + '.png')\n",
    "            image = cv2.resize(image,  self._dim) \n",
    "            \n",
    "            if self.transform is not None:\n",
    "                if np.random.rand() > 0.7:\n",
    "                    # albumentation : grid mask\n",
    "                    res = self.transform(image=image)\n",
    "                    image = res['image']\n",
    "                else:\n",
    "                    # augmix augmentation\n",
    "                    image = augment_and_mix(image)\n",
    "            \n",
    "            # scaling  이거 지우면 scaling 안한 파일이 들어감\n",
    "            image = (image.astype(np.float32)/255.0 - stats[0])/stats[1]\n",
    "            \n",
    "            # gray scaling 128x128\n",
    "            gray = lambda rgb : np.dot(rgb[... , :3] , [0.299 , 0.587, 0.114]) \n",
    "            image = gray(image) \n",
    "            \n",
    "            # expand the axises , 128x128x3 만들기\n",
    "            \n",
    "            image = image.reshape(-1,128,128,1)\n",
    "            image = np.concatenate((image,)*3, axis=-1)\n",
    "\n",
    "            Data[i,:, :, :] =  image\n",
    "        \n",
    "            Target_1[i,:] = self._label_1.loc[k, :].values\n",
    "            Target_2[i,:] = self._label_2.loc[k, :].values\n",
    "            Target_3[i,:] = self._label_3.loc[k, :].values\n",
    "            \n",
    "        return Data, [Target_1, Target_2, Target_3]\n",
    "    \n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self._indices = np.arange(len(self._list_idx))\n",
    "        if self._shuffle:\n",
    "            np.random.shuffle(self._indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epoch = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    }
   ],
   "source": [
    "history = {}\n",
    "\n",
    "for i in range(4):\n",
    "    \n",
    "    # train_128_i 접속\n",
    "    im_path = f'./bengaliai_cv19/train_128_{i}/'\n",
    "    \n",
    "    # add filename to train_df_ \n",
    "    train_df_ = train_df_[i*50210:(i+1)*50210]\n",
    "    train_df_['filename'] = train_df_.image_id.apply(lambda filename: im_path + filename + '.png')\n",
    "\n",
    "    \n",
    "    # grid mask augmentation\n",
    "    transforms_train = albumentations.Compose([\n",
    "        GridMask(num_grid=3, rotate=15, p=1),\n",
    "    ])\n",
    "\n",
    "    # for way one - data generator\n",
    "    train_labels, val_labels = train_test_split(train_df_, test_size = 0.10, random_state = SEED,\n",
    "                                            stratify = train_df_[['grapheme_root', \n",
    "                                                              'vowel_diacritic', \n",
    "                                                              'consonant_diacritic']])\n",
    "    \n",
    "    # training generator\n",
    "    train_generator = GraphemeGenerator(train_labels, batch_size, dim, \n",
    "                                shuffle = True, transform=transforms_train)\n",
    "\n",
    "    # validation generator: no shuffle , not augmentation\n",
    "    val_generator = GraphemeGenerator(val_labels, batch_size, dim, \n",
    "                              shuffle = False)\n",
    "    \n",
    "    \n",
    "    # Fit the model\n",
    "    history = model.fit_generator(train_generator,steps_per_epoch=int(len(train_labels)/batch_size), validation_data=val_generator,validation_steps = int(len(val_labels)/batch_size),epochs=epoch,callbacks=[ModelCheckpointFull(RUN_NAME + 'model_' + str(epoch) + '.h5')],verbose = 1)\n",
    "    \n",
    "    # Set and Concat Training History\n",
    "    temp_history = model.history.history\n",
    "    if epoch == 0:\n",
    "        history = temp_history\n",
    "    else:\n",
    "        for k in temp_history: history[k] = history[k] + temp_history[k]\n",
    "\n",
    "    # Custom ReduceLRonPlateau\n",
    "    CustomReduceLRonPlateau(model, history, epoch)\n",
    "\n",
    "    # Cleanup\n",
    "    del data_generator_train, data_generator_val, train_idx, valid_idx\n",
    "    gc.collect()\n",
    "    # Delete to reduce memory usage\n",
    "    \n",
    "\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-0d8deb6b9118>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Plot Training Summaries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplot_summaries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPLOT_NAME1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPLOT_NAME2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Create Predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mrow_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot Training Summaries\n",
    "plot_summaries(history, PLOT_NAME1, PLOT_NAME2)\n",
    "\n",
    "# Create Predictions\n",
    "row_ids, targets = [], []\n",
    "id = 0\n",
    "\n",
    "# Loop through parquet files\n",
    "for i in range(4):\n",
    "    img_df = pd.read_parquet(os.path.join(DATA_DIR, 'test_image_data_'+str(i)+'.parquet'))\n",
    "    img_df = img_df.drop('image_id', axis = 1)\n",
    "    \n",
    "    # Loop through rows in parquet file\n",
    "    for index, row in img_df.iterrows():\n",
    "        img = resize_image(row.values, WIDTH, HEIGHT, WIDTH_NEW, HEIGHT_NEW)\n",
    "        img = np.stack((img,)*CHANNELS, axis=-1)\n",
    "        image = img.reshape(-1, HEIGHT_NEW, WIDTH_NEW, 3)\n",
    "        \n",
    "        # Predict\n",
    "        preds = model.predict(image, verbose = 1)\n",
    "        for k in range(3):\n",
    "            row_ids.append('Test_' + str(id) + '_' + tgt_cols[k])\n",
    "            targets.append(np.argmax(preds[k]))\n",
    "        id += 1\n",
    "\n",
    "# Create and Save Submission File\n",
    "submission = pd.DataFrame({'row_id': row_ids, 'target': targets}, columns = ['row_id', 'target'])\n",
    "submission.to_csv('submission.csv', index = False)\n",
    "print(submission.head(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "pyarrow is required for parquet support\n\nyou can install via conda\nconda install pyarrow -c conda-forge\n\nor via pip\npip install -U pyarrow\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m             \u001b[1;32mimport\u001b[0m \u001b[0mpyarrow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mpyarrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyarrow'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-9b1c87fa6892>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPyArrowImpl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m             raise ImportError(\n\u001b[1;32m---> 86\u001b[1;33m                 \u001b[1;34m\"pyarrow is required for parquet support\\n\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m                 \u001b[1;34m\"you can install via conda\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[1;34m\"conda install pyarrow -c conda-forge\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: pyarrow is required for parquet support\n\nyou can install via conda\nconda install pyarrow -c conda-forge\n\nor via pip\npip install -U pyarrow\n"
     ]
    }
   ],
   "source": [
    "pd.io.parquet.PyArrowImpl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "i= 1\n",
    "img_df = pd.read_parquet(os.path.join(DATA_DIR, 'test_image_data_'+str(i)+'.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 32333)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
